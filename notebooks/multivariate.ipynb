{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Multivariate inference\n",
    "\n",
    "## Markov Chain Monte Carlo methods\n",
    "\n",
    "- MCMC methods can be used to estimate the posterior in an efficient way\n",
    "- In MCMC, the goal is to generate chains that after some iterations start sampling from the posterior\n",
    "- The posterior densities are then obtained in a Monte Carlo way: $\\rho_{\\delta}({ \\mathbf{\\theta}}) = m({\\mathbf{\\theta}_{\\delta}})/n$\n",
    "- A popular approach for MCMC is the Metropolis-Hastings algorithm: \n",
    "\n",
    "```{figure} ../figures/mcmc_algo.png\n",
    ":alt: mcm algo\n",
    ":width: 600px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "````{exercise}\n",
    ":label: exercise6\n",
    ":number: 6\n",
    "Solve [exercise 5](#exercise5), but with 3 parameters: \n",
    "\n",
    "```{figure} ../figures/mutivariate_inference.png\n",
    ":alt: mcm algo\n",
    ":width: 300px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "Assume:\n",
    "- Prior $E$ ~ $N(60,20)$ GPa\n",
    "- Prior $Q$ ~ $N(60,30)$ kN\n",
    "- Prior $x_Q$ ~ $U(0,10000)$ mm\n",
    "\n",
    "Obtain: \n",
    "- Posterior distribution \n",
    "- Pair-plot\n",
    "- Trace-plot\n",
    "- Posterior predictive \n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{hint}\n",
    ":class: dropdown\n",
    "\n",
    "```{figure} ../figures/mutivariate_hint.png\n",
    ":alt: mcm algo\n",
    ":width: 600px\n",
    ":align: center\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ":::{tip}\n",
    ":class: dropdown\n",
    "**Tips for working with emcee**\n",
    "\n",
    "Tuning algorithm:\n",
    "- Rule of thumb: $n_{walkers} = 10* n_{params}$\n",
    "- Make sure that the likelihood is supported in the entire prior domain (not â€˜nansâ€™)\n",
    "\n",
    "Convergence:\n",
    "- We define a burn-in phase to discard samples still correlated to initial points\n",
    "- Number of initial samples (burn-in phase) ïƒ  Difficult to define a priori\n",
    "- Always check with Trace plots\n",
    "- Once converged, only a few steps (e.g. 100) are needed for most relevant metrics\n",
    "\n",
    "Advanced topics:\n",
    "- Read the emcee paper: [emcee: The MCMC Hammer](https://arxiv.org/abs/1202.3665)\n",
    "- [Autocorrelation analysis & convergence â€” emcee](https://emcee.readthedocs.io/en/stable/tutorials/autocorr/)\n",
    "- [Parallelization â€” emcee](https://emcee.readthedocs.io/en/stable/tutorials/parallel/)\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Problem definition\n",
    "from probeye.definition.inverse_problem import InverseProblem\n",
    "from probeye.definition.forward_model import ForwardModelBase\n",
    "from probeye.definition.distribution import Normal, Uniform\n",
    "from probeye.definition.sensor import Sensor\n",
    "from probeye.definition.likelihood_model import GaussianLikelihoodModel\n",
    "from probeye.definition.correlation_model import ExpModel\n",
    "\n",
    "# Inference\n",
    "from probeye.inference.emcee.solver import EmceeSolver\n",
    "\n",
    "# Postprocessing\n",
    "from probeye.postprocessing.sampling_plots import create_pair_plot\n",
    "from probeye.postprocessing.sampling_plots import create_posterior_plot\n",
    "from probeye.postprocessing.sampling_plots import create_trace_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed parameters\n",
    "I = 1e9  # mm^4\n",
    "L = 10_000  # mm\n",
    "\n",
    "# Measurements\n",
    "x_sensors = [2500, 5000]  # mm  (always from lower to higher, bug in inv_cov_vec_1D in tripy)\n",
    "d_sensors = [35, 50]  # mm\n",
    "sigma_model = 2.5  # mm\n",
    "pearson = 0.5\n",
    "l_corr = -np.abs(x_sensors[1] - x_sensors[0]) / np.log(pearson)  # mm (assuming exponential correlation)\n",
    "\n",
    "# Prior\n",
    "E_mean = 60  # GPa\n",
    "E_std = 20  # GPa\n",
    "Q_mean = 60  # kN\n",
    "Q_std = 30  # kN\n",
    "Q_loc_low = 0  # mm\n",
    "Q_loc_high = 10000  # mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_deflection(E, Q, a, x):  # a is load position, x is sensor position\n",
    "    if x < a:\n",
    "        b = L - a\n",
    "        return Q * b * x * (L ** 2 - b ** 2 - x ** 2) / (6 * E * I * L)\n",
    "    \n",
    "    return Q * a * (L - x) * (2 * L * x - x ** 2 - a ** 2) / (6 * E * I * L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code where the three dots are\n",
    "\n",
    "class BeamModel(ForwardModelBase):\n",
    "    def interface(self):\n",
    "        self.parameters = ...\n",
    "        self.input_sensors = Sensor(\"x\")\n",
    "        self.output_sensors = Sensor(\"y\", std_model=\"sigma\")\n",
    "\n",
    "    def response(self, inp: dict) -> dict:\n",
    "        return {...}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define inverse problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code where the three dots are\n",
    "\n",
    "# Instantiate the inverse problem\n",
    "problem = InverseProblem(...)\n",
    "\n",
    "# Add latent parameters\n",
    "problem.add_parameter(\n",
    "    ...\n",
    ")\n",
    "problem.add_parameter(\n",
    "    ...\n",
    ")\n",
    "problem.add_parameter(\n",
    "  ...\n",
    ")\n",
    "\n",
    "# Add fixed parameters\n",
    "problem.add_parameter(\n",
    " ...\n",
    ")\n",
    "problem.add_parameter(\n",
    "...\n",
    ")\n",
    "\n",
    "# Add measurement data\n",
    "problem.add_experiment(\n",
    "...\n",
    ")\n",
    "                 \n",
    "# Add forward model\n",
    "problem.add_forward_model(...)\n",
    "\n",
    "# Add likelihood model\n",
    "likelihood_model = GaussianLikelihoodModel(\n",
    "        ...\n",
    "        )\n",
    "problem.add_likelihood_model(likelihood_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve with MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emcee_solver = EmceeSolver(problem, show_progress=True)\n",
    "inference_data = emcee_solver.run(n_steps=2000, n_initial_steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_plot_array = create_posterior_plot(\n",
    "    inference_data,\n",
    "    emcee_solver.problem,\n",
    "    kind=\"kde\",\n",
    "    title=\"Kernel density estimate of the posterior distribution\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_plot_array = create_pair_plot(\n",
    "    inference_data,\n",
    "    emcee_solver.problem,\n",
    "    focus_on_posterior=True,\n",
    "    show_legends=True,\n",
    "    title=\"Pair plot of the posterior distribution\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code where the three dots are\n",
    "\n",
    "trace_plot_array = create_trace_plot(\n",
    "   ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior predictives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code where the three dots are\n",
    "\n",
    " # Extract samples\n",
    "posterior_samples = inference_data.posterior.to_array()  # parameters, chains, samples\n",
    "posterior_samples = np.array(posterior_samples)\n",
    "posterior_samples = posterior_samples.reshape(posterior_samples.shape[0], -1).T  # samples, parameters\n",
    "\n",
    "# Make predictions for x in the range of the beam\n",
    "x_range = np.linspace(0, 10000, 100)\n",
    "predictions = np.zeros((len(posterior_samples), len(x_range)))\n",
    "\n",
    "for i, sample in enumerate(posterior_samples):\n",
    "    ...\n",
    "\n",
    "# Calculate mean and 95% intervals\n",
    "mean_pred = ...\n",
    "lower_bound = ...  # 2.5th percentile\n",
    "upper_bound = ...  # 97.5th percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot posterior predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(x_range, -mean_pred, label='Mean Prediction')\n",
    "plt.fill_between(x_range, -lower_bound, -upper_bound, color='lightblue', alpha=0.5, label='95% Interval')\n",
    "plt.xlabel('x (mm)')\n",
    "plt.ylabel('Deflection')\n",
    "plt.title('Posterior Predictive Deflections along the Beam')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note} Complete Code! ðŸ“ƒðŸ’»\n",
    ":class: dropdown\n",
    "Hereâ€™s the complete code that you would run in your PC:\n",
    "\n",
    "```python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Problem definition\n",
    "from probeye.definition.inverse_problem import InverseProblem\n",
    "from probeye.definition.forward_model import ForwardModelBase\n",
    "from probeye.definition.distribution import Normal, Uniform\n",
    "from probeye.definition.sensor import Sensor\n",
    "from probeye.definition.likelihood_model import GaussianLikelihoodModel\n",
    "from probeye.definition.correlation_model import ExpModel\n",
    "\n",
    "# Inference\n",
    "from probeye.inference.emcee.solver import EmceeSolver\n",
    "\n",
    "# Postprocessing\n",
    "from probeye.postprocessing.sampling_plots import create_pair_plot\n",
    "from probeye.postprocessing.sampling_plots import create_posterior_plot\n",
    "from probeye.postprocessing.sampling_plots import create_trace_plot\n",
    "\n",
    "# Fixed parameters\n",
    "I = 1e9  # mm^4\n",
    "L = 10_000  # mm\n",
    "\n",
    "# Measurements\n",
    "x_sensors = [2500, 5000]  # mm  (always from lower to higher, bug in inv_cov_vec_1D in tripy)\n",
    "d_sensors = [35, 50]  # mm\n",
    "sigma_model = 2.5  # mm\n",
    "pearson = 0.5\n",
    "l_corr = -np.abs(x_sensors[1] - x_sensors[0]) / np.log(pearson)  # mm (assuming exponential correlation)\n",
    "\n",
    "# Prior\n",
    "E_mean = 60  # GPa\n",
    "E_std = 20  # GPa\n",
    "Q_mean = 60  # kN\n",
    "Q_std = 30  # kN\n",
    "Q_loc_low = 0  # mm\n",
    "Q_loc_high = 10000  # mm\n",
    "\n",
    "\n",
    "def beam_deflection(E, Q, a, x):  # a is load position, x is sensor position\n",
    "    if x < a:\n",
    "        b = L - a\n",
    "        return Q * b * x * (L ** 2 - b ** 2 - x ** 2) / (6 * E * I * L)\n",
    "    \n",
    "    return Q * a * (L - x) * (2 * L * x - x ** 2 - a ** 2) / (6 * E * I * L)\n",
    "\t\n",
    "\t\n",
    "class BeamModel(ForwardModelBase):\n",
    "    def interface(self):\n",
    "        self.parameters = [\"E\", \"Q\", \"a\"]\n",
    "        self.input_sensors = Sensor(\"x\")\n",
    "        self.output_sensors = Sensor(\"y\", std_model=\"sigma\")\n",
    "\n",
    "    def response(self, inp: dict) -> dict:\n",
    "        E = inp[\"E\"]\n",
    "        Q = inp[\"Q\"]\n",
    "        a = inp[\"a\"]\n",
    "        x = inp[\"x\"]\n",
    "        return {\"y\": [beam_deflection(E, Q, a, float(x[0])), beam_deflection(E, Q, a, float(x[1]))]}  # float() needed, probably a bug in probeye\n",
    "\t\t\n",
    "\t\t\n",
    "# Instantiate the inverse problem\n",
    "problem = InverseProblem(\"Beam model with two sensors\", print_header=False)\n",
    "\n",
    "# Add latent parameters\n",
    "problem.add_parameter(\n",
    "    \"E\",\n",
    "    tex=\"$E$\",\n",
    "    info=\"Elastic modulus of the beam (GPa)\",\n",
    "    prior=Normal(mean=E_mean, std=E_std),\n",
    ")\n",
    "problem.add_parameter(\n",
    "    \"Q\",\n",
    "    tex=\"$Q$\",\n",
    "    info=\"Load applied to the beam (kN)\",\n",
    "    prior=Normal(mean=Q_mean, std=Q_std),\n",
    ")\n",
    "problem.add_parameter(\n",
    "    \"a\",\n",
    "    tex=\"$a$\",\n",
    "    info=\"Position of the load (mm)\",\n",
    "    prior=Uniform(low=Q_loc_low, high=Q_loc_high)\n",
    ")\n",
    "\n",
    "# Add fixed parameters\n",
    "problem.add_parameter(\n",
    "    \"sigma\",\n",
    "    tex=\"$\\sigma$\",\n",
    "    info=\"Standard deviation of the model error (mm)\",\n",
    "    value=sigma_model,\n",
    ")\n",
    "problem.add_parameter(\n",
    "    \"l_corr\",\n",
    "    tex=\"$l_{corr}$\",\n",
    "    info=\"Correlation length of the model error (mm)\",\n",
    "    value=l_corr,\n",
    ")\n",
    "\n",
    "# Add measurement data\n",
    "problem.add_experiment(\n",
    "    name=\"TestSeries_1\",\n",
    "    sensor_data={\"x\": x_sensors, \"y\": d_sensors}\n",
    ")\n",
    "                 \n",
    "# Add forward model\n",
    "problem.add_forward_model(BeamModel(\"BeamModel\"), experiments=\"TestSeries_1\")\n",
    "\n",
    "# Add likelihood model\n",
    "likelihood_model = GaussianLikelihoodModel(\n",
    "        experiment_name=\"TestSeries_1\", \n",
    "        model_error=\"additive\",\n",
    "        correlation=ExpModel(x=\"l_corr\")\n",
    "        )\n",
    "problem.add_likelihood_model(likelihood_model)\n",
    "\n",
    "#solve mcmc\n",
    "emcee_solver = EmceeSolver(problem, show_progress=True)\n",
    "inference_data = emcee_solver.run(n_steps=2000, n_initial_steps=2000)\n",
    "\n",
    "\n",
    "#posterior plot\n",
    "post_plot_array = create_posterior_plot(\n",
    "    inference_data,\n",
    "    emcee_solver.problem,\n",
    "    kind=\"kde\",\n",
    "    title=\"Kernel density estimate of the posterior distribution\",\n",
    ")\n",
    "\n",
    "#pair plot\n",
    "pair_plot_array = create_pair_plot(\n",
    "    inference_data,\n",
    "    emcee_solver.problem,\n",
    "    focus_on_posterior=True,\n",
    "    show_legends=True,\n",
    "    title=\"Pair plot of the posterior distribution\",\n",
    ")\n",
    "\n",
    "#trace plot\n",
    "trace_plot_array = create_trace_plot(\n",
    "    inference_data,\n",
    "    emcee_solver.problem,\n",
    "    title=\"Trace plot of the posterior distribution\",\n",
    ")\n",
    "\n",
    "#Posterior predictives\n",
    "# Extract samples\n",
    "posterior_samples = inference_data.posterior.to_array()  # parameters, chains, samples\n",
    "posterior_samples = np.array(posterior_samples)\n",
    "posterior_samples = posterior_samples.reshape(posterior_samples.shape[0], -1).T  # samples, parameters\n",
    "\n",
    "# Make predictions for x in the range of the beam\n",
    "x_range = np.linspace(0, 10000, 100)\n",
    "predictions = np.zeros((len(posterior_samples), len(x_range)))\n",
    "\n",
    "for i, sample in enumerate(posterior_samples):\n",
    "    E = sample[0]\n",
    "    Q = sample[1]\n",
    "    a = sample[2]\n",
    "    predictions[i, :] = [beam_deflection(E, Q, a, x) for x in x_range]\n",
    "\n",
    "# Calculate mean and 95% intervals\n",
    "mean_pred = np.mean(predictions, axis=0)\n",
    "lower_bound = np.percentile(predictions, 2.5, axis=0)\n",
    "upper_bound = np.percentile(predictions, 97.5, axis=0)\n",
    "\n",
    "\n",
    "#Plot posterior predictive\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(x_range, -mean_pred, label='Mean Prediction')\n",
    "plt.fill_between(x_range, -lower_bound, -upper_bound, color='lightblue', alpha=0.5, label='95% Interval')\n",
    "plt.xlabel('x (mm)')\n",
    "plt.ylabel('Deflection')\n",
    "plt.title('Posterior Predictive Deflections along the Beam')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
